{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10c5622a-d323-4789-9efb-f46b87948801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from repliclust import Archetype, DataGenerator, set_seed\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import adjusted_mutual_info_score as ami\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "PCT = 0.025\n",
    "\n",
    "def carry_out_benchmark(X, y, archetype):\n",
    "    gauss = GaussianMixture(n_components=archetype.n_clusters,\n",
    "                            max_iter=500, n_init=10,\n",
    "                            init_params=\"kmeans\")\n",
    "    kmeans = KMeans(n_clusters=archetype.n_clusters,\n",
    "                    max_iter=500, n_init=10,\n",
    "                    init=\"k-means++\")\n",
    "\n",
    "    y_hat_kmeans = kmeans.fit_predict(X)\n",
    "    ami_kmeans = ami(y, y_hat_kmeans)\n",
    "    y_hat_gauss = gauss.fit_predict(X)\n",
    "    ami_gauss = ami(y, y_hat_gauss)\n",
    "\n",
    "    return (ami_kmeans, ami_gauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38d5cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Archetypes for Figure 11\n",
    "\n",
    "samples_per_cluster = 100 # vary this number on {100, 200, 1000} to reproduce paper\n",
    "\n",
    "highdim_shallow = Archetype(dim=200, n_clusters=10, n_samples=10*samples_per_cluster, distributions=['normal'],\n",
    "                            name='highdim_shallow')\n",
    "expon_highoverlap = Archetype(dim=10, n_clusters=5, n_samples=5*samples_per_cluster, max_overlap=(1+PCT)*0.20, min_overlap=(1-PCT)*0.20,\n",
    "                              distributions=['exponential'],\n",
    "                              name='expon_highoverlap')\n",
    "normal_highlyvariable = Archetype(dim=10, n_clusters=7, n_samples=7*samples_per_cluster, radius_maxmin=10, imbalance_ratio=10,\n",
    "                                  aspect_ref=3, aspect_maxmin=10, distributions=['normal'],\n",
    "                                  name='normal_highlyvariable')\n",
    "nonnormal_highlyvariable = Archetype(dim=10, n_clusters=7, n_samples=7*samples_per_cluster, radius_maxmin=10, imbalance_ratio=10,\n",
    "                                  aspect_ref=3, aspect_maxmin=10, distributions=['exponential'],\n",
    "                                  name='nonnormal_highlyvariable')\n",
    "normal_easy = Archetype(dim=10, n_clusters=7, n_samples=7*samples_per_cluster, radius_maxmin=1, imbalance_ratio=1,\n",
    "                                  aspect_ref=1, aspect_maxmin=1, name='normal_easy', \n",
    "                                  distributions=['normal'])\n",
    "heavytailed = Archetype(dim=10, n_clusters=5, n_samples=5*samples_per_cluster, distributions=[('standard_t', {'df': 2})],\n",
    "                        name='heavytailed')\n",
    "\n",
    "archetype_collection = [highdim_shallow, expon_highoverlap, normal_highlyvariable, normal_easy, heavytailed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0af50f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Archetypes for Figure 12\n",
    "\n",
    "data_pts_per_cluster = 1000 # vary this number on {100, 200, 1000} to reproduce paper\n",
    "\n",
    "normal_highlyvariable = Archetype(dim=10, n_clusters=7, n_samples=7*data_pts_per_cluster, radius_maxmin=10, imbalance_ratio=10,\n",
    "                                  aspect_ref=3, aspect_maxmin=10, distributions=['normal'],\n",
    "                                  name='normal_highlyvariable')\n",
    "nonnormal_highlyvariable = Archetype(dim=10, n_clusters=7, n_samples=7*data_pts_per_cluster, radius_maxmin=10, imbalance_ratio=10,\n",
    "                                  aspect_ref=3, aspect_maxmin=10, distributions=['exponential'],\n",
    "                                  name='nonnormal_highlyvariable')\n",
    "heavytails_soft_highlyvariable = Archetype(dim=10, n_clusters=7, n_samples=7*data_pts_per_cluster, radius_maxmin=10, imbalance_ratio=10,\n",
    "                                  aspect_ref=3, aspect_maxmin=10,\n",
    "                                  distributions=[('standard_t', {'df': 4})],\n",
    "                                  name='heavytails_soft_highlyvariable')\n",
    "heavytails_med_highlyvariable = Archetype(dim=10, n_clusters=7, n_samples=7*data_pts_per_cluster, radius_maxmin=10, imbalance_ratio=10,\n",
    "                                  aspect_ref=3, aspect_maxmin=10,\n",
    "                                  distributions=[('standard_t', {'df': 3})],\n",
    "                                  name='heavytails_med_highlyvariable')\n",
    "heavytails_hard_highlyvariable = Archetype(dim=10, n_clusters=7, n_samples=7*data_pts_per_cluster, radius_maxmin=10, imbalance_ratio=10,\n",
    "                                  aspect_ref=3, aspect_maxmin=10,\n",
    "                                  distributions=[('standard_t', {'df': 2})],\n",
    "                                  name='heavytails_hard_highlyvariable')\n",
    "heavytails_hardhard_highlyvariable = Archetype(dim=10, n_clusters=7, n_samples=7*data_pts_per_cluster, radius_maxmin=10, imbalance_ratio=10,\n",
    "                                  aspect_ref=3, aspect_maxmin=10,\n",
    "                                  distributions=[('standard_t', {'df': 1.5})],\n",
    "                                  name='heavytails_hardhard_highlyvariable')\n",
    "heavytails_hardhardhard_highlyvariable = Archetype(dim=10, n_clusters=7, n_samples=7*data_pts_per_cluster, radius_maxmin=10, imbalance_ratio=10,\n",
    "                                  aspect_ref=3, aspect_maxmin=10,\n",
    "                                  distributions=[('standard_t', {'df': 1.0})],\n",
    "                                  name='heavytails_hardhardhard_highlyvariable')\n",
    "highlyvariable_archetypes = [normal_highlyvariable,\n",
    "                             nonnormal_highlyvariable,\n",
    "                             heavytails_med_highlyvariable,\n",
    "                             heavytails_hard_highlyvariable,\n",
    "                             heavytails_hardhard_highlyvariable\n",
    "                             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa84e83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 457.78it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 10605.16it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 2027.11it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 8589.90it/s, Status=SUCCESS] \n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 11457.86it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 2200.35it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 10959.29it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 7023.95it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 8829.06it/s, Status=SUCCESS] \n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 18925.09it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 1146.42it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 9866.47it/s, Status=SUCCESS] \n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 6424.90it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 12827.14it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 33633.36it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 3940.68it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 5030.17it/s, Status=SUCCESS] \n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 6609.99it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 2725.49it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 13352.84it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 1111.10it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 13148.70it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 10426.85it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 11315.06it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 31390.58it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 425.08it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 15937.82it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 4308.49it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 13564.73it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 20474.67it/s, Status=SUCCESS]\n",
      "Optimizing Cluster Centers: 100%|██████████| 300/300 [00:00<00:00, 668.61it/s, Status=SUCCESS]\n"
     ]
    }
   ],
   "source": [
    "### Carry out the benchmark(s)\n",
    "\n",
    "N_REPL = 300\n",
    "collection = archetype_collection # change to highlyvariable_archetypes for second study\n",
    "n_archetypes = len(collection)\n",
    "dg = DataGenerator(collection)\n",
    "\n",
    "data = []\n",
    "\n",
    "for X, y, archetype in dg(n_datasets=N_REPL*n_archetypes, quiet=False):\n",
    "    # carry out benchmark\n",
    "    kmeans_result, gauss_result = carry_out_benchmark(X,y,archetype)\n",
    "\n",
    "    # store the results\n",
    "    data.append((kmeans_result, gauss_result, archetype.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76530037",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create data frame and save the data to disk\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data, columns=['kmeans', 'gauss', 'archetype'])\n",
    "# df.to_csv('gmm-vs-kmeans-benchmark-100percluster.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "04c324528789c96162d5b760c5e7a3821806023cce149d3bc5672220374d5bff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
